# NOVA: Modular Voice-Based AI Assistant

> Intelligent desktop assistant built for **offline-first, modular, and personalized use**, featuring voice activation, dynamic skill execution, persistent memory, and future-ready NLP.

---

## ğŸ§  Overview

NOVA is a modular, voice-based desktop assistant designed to be responsive, customizable, and privacy-respecting. It supports wake-word activation, modular skills, local memory-based personalization, and context-aware interactions. Built with PyQt5 and Python 3, NOVA is designed for desktop environments without requiring persistent cloud connectivity.

---

## ğŸ“ Project Structure

```bash
NOVA/
â”œâ”€â”€ main.py                 # Launches GUI and core modules
â”œâ”€â”€ core/                   # All critical system modules
â”‚   â”œâ”€â”€ wake_word.py        # Wake-word detection (Porcupine/Google)
â”‚   â”œâ”€â”€ stt.py              # Speech-to-text (Whisper/Google)
â”‚   â”œâ”€â”€ nlp.py              # Intent recognition (Spacy + Rules)
â”‚   â”œâ”€â”€ skill_manager.py    # Skill discovery and execution
â”‚   â”œâ”€â”€ memory_manager.py   # Persistent user context (ChromaDB)
â”‚   â”œâ”€â”€ mood.py             # Mood/emotion detection (WIP)
â”‚   â”œâ”€â”€ tts.py              # Text-to-speech (pyttsx3)
â”œâ”€â”€ features/               # User-defined skill scripts (Legacy support)
â”œâ”€â”€ config/                 # API keys, constants
â”œâ”€â”€ utils/images/           # Loading GIFs for UI
â””â”€â”€ tests/                  # Unit tests for core logic
```

---

## ğŸ”§ Installation

### Prerequisites:
- Python 3.9+ (Python 3.11 recommended for full compatibility)
- FFmpeg (for Whisper STT)
- Virtualenv (optional but recommended)

### Dependencies

```bash
pip install -r requirements.txt
```

**External Requirements:**
- `pvporcupine` for hotword detection (Requires AccessKey)
- `ffmpeg` for Whisper
- API keys if you plan to use web-based skills (e.g., Google Calendar)

---

## ğŸš€ How to Run

1. **Activate Environment** (if using `fix_env.sh`):
   ```bash
   source venv/bin/activate
   ```
2. **Run Main**:
   ```bash
   python main.py
   ```

**Once the GUI loads:**
1. Wait for it to initialize (Status: "Listening for 'Hey NOVA'...")
2. Speak the wake word: **"Porcupine"** (Default) or **"Hey NOVA"**
3. Ask a command like:
   - "What is the time?"
   - "Play lo-fi on YouTube"
   - "What's the weather in Dallas?"

---

## ğŸ§© Core Functionalities

### âœ… 1. Wake Word Activation (`core/wake_word.py`)
- Passive listener for the phrase â€œHey NOVAâ€ / "Porcupine".
- Runs in background thread (`WakeWordListener`).
- **Engine**: Porcupine (High Accuracy).

### âœ… 2. Speech-to-Text (`core/stt.py`)
- Converts audio to text using **Whisper** (Local, default) or Google STT (fallback).
- Emits transcribed text to NLP module via event signal.

### âœ… 3. Intent Recognition (`core/nlp.py`)
- Hybrid System:
  - **Spacy**: For Entity Recognition (extracting "Dallas" from "Weather in Dallas").
  - **Rules**: For critical commands ("time", "youtube").
- Future upgrade planned: DistilBERT / GPT prompt chaining.

### âœ… 4. Skill Manager (`core/skill_manager.py`)
- Dynamically loads and executes Python scripts from `features/`.
- **Note**: Some legacy skills need refactoring to return values instead of printing.

### âœ… 5. Memory Manager (`core/memory_manager.py`)
- **Engine**: **ChromaDB** (Vector Database).
- Stores: Past commands, Mood state, User preferences.
- Supports: Embedding lookup and contextual recall.

### âœ… 6. Mood Detection (`core/mood.py`)
- Placeholder logic for sentiment analysis via Tone in speech or Entity-based sentiment.
- Affects assistant response tone.

### âœ… 7. Text-to-Speech (`core/tts.py`)
- Converts system response into speech.
- **Backend**: `pyttsx3` (Offline).
- Executed on a separate thread to avoid blocking GUI.

### âœ… 8. GUI (`main.py` & `features/gui.py`)
- **Framework**: PyQt5.
- **Dashboard**:
  - Conversation history panel.
  - Live assistant status / voice interaction.
  - Skills tab + command builder.

---

## ğŸ› ï¸ Skills (Features)

Located in `features/`. Each file corresponds to a user-executable "skill."

| File | Intent | Sample Query |
| :--- | :--- | :--- |
| `weather.py` | `get_weather` | "What's the weather today?" |
| `youtube_search.py` | `play_youtube` | "Play lo-fi hip hop on YouTube" |
| `google_calendar.py` | `check_calendar` | "What do I have tomorrow?" |
| `note.py` | `take_note` | "Take a note: buy protein" |
| `send_email.py` | `send_email` | "Send an email to Eric" |

> **âš ï¸ Note**: Legacy skill scripts currently print to stdout. Work is underway to refactor them to return strings for the GUI.

---

## ğŸ§ª Testing

Unit tests are located in `tests/`.

To run:
```bash
python -m unittest discover tests
```

**Covers:**
- Intent parsing (`NLPHandler`)
- Basic skill routing (`SkillManager`)
- Memory storage/retrieval (`MemoryManager`)

---

## ğŸ“¹ Phase 4 Deliverables (Required)

- âœ… **Communication Diagram** â€“ Shows module interactions.
- âœ… **UI Code** â€“ Located in `features/gui.py`.
- âœ… **Demo Recording** â€“ Use `main.py` to demonstrate Wake Word + STT + Skill Execution.

---

## ğŸ”® Planned Features (Roadmap)

- [ ] **Refactor Skills**: Convert scripts to callable functions.
- [ ] **Plugin Loader**: Add/remove modules on the fly via GUI.
- [ ] **Web Dashboard**: Remote voice logs.
- [ ] **Mood Tracker**: Visual interface for detected sentiment.

---

## ï¿½ Contributing

You can add new features by:
1. Creating a new `.py` in `/features`.
2. Registering its intent in `core/nlp.py`.
3. Updating `SkillManager` to route it.

---

## ğŸ” Local-First & Privacy

- No audio data or logs are sent externally.
- Whisper STT runs locally.
- MemoryManager uses local vector DB (ChromaDB).
- Optional cloud APIs (e.g., Google Calendar) are opt-in only.

---

## ğŸ§¾ License

MIT â€” Built for educational and research purposes.
